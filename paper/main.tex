\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[IL2]{fontenc}
\usepackage[czech]{babel}

\usepackage[a4paper,top=3cm,bottom=4cm,left=3.5cm,right=3cm,marginparwidth=1.75cm]{geometry}

\usepackage{amsmath}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{listings}
\usepackage{color}


% DON'T HYPHENATE THESE PLEASE
\hyphenation{JavaScript}

% CODE LISTING CONFIG
\definecolor{lightgray}{rgb}{.9,.9,.9}
\definecolor{orange}{rgb}{.694,.369,.236}
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{darkbrown}{rgb}{.655,.349,.125}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}
\definecolor{darkgreen}{rgb}{.298, .565, .404}

\lstdefinelanguage{JavaScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={require, then, start, create, echo, run, class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkbrown}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{darkgreen}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}
\lstset{
   language=JavaScript,
   backgroundcolor=\color{white},
   extendedchars=true,
   basicstyle=\footnotesize\ttfamily,
   showstringspaces=false,
   showspaces=false,
   numbers=left,
   numberstyle=\footnotesize,
   numbersep=9pt,
   tabsize=2,
   breaklines=true,
   showtabs=false,
   captionpos=b
}

\renewcommand{\lstlistingname}{Ukázka kódu}% Listing -> Algorithm
\renewcommand{\lstlistlistingname}{Seznam ukázek kódů \lstlistingname s}

\newcommand{\HRule}[1]{\rule{\linewidth}{#1}}           % Horizontal rule

\makeatletter                                           % Title
\def\printtitle{                       
    {\centering \@title\par}}
\makeatother                                    

\makeatletter                                           % Author
\def\printauthor{                   
    {\centering \large \@author}}                
\makeatother                            

\title{   \normalsize\textsc {
          \large{Vysoká škola ekonomická v~Praze}\\[0.3cm]    
          \large{Fakulta informatiky a~statistiky}\\[0.3cm]
          \large{Katedra informačního a~znalostního inženýrství}\\
        }
\textsc{}                                               % Subtitle
            \\[7.0cm]                                   % 2cm spacing
            \huge \textbf{Web Scraping s~CasperJS}      % Title
            \HRule{2pt} \\ [0.4cm]                      % Lower rule + 0.5cm spacing
            \normalsize \textbf{4IZ470 Dolování znalostí z~webu}
        }

\author{\raggedright
        \normalsize
        Student: Bc. Viet Bach Nguyen \\
        \normalsize
        Vyučující: doc. Ing. Vojtěch Svátek, Dr. \\
        \normalsize 
        Datum: \today
}

\setlength{\parskip}{0.5em}
\setlength{\parindent}{2em}
\renewcommand{\baselinestretch}{1.2}

\begin{document}

\thispagestyle{empty}           % Remove page numbering on this page

\printtitle                     % Print the title data as defined above
      \vfill
\printauthor                    % Print the author data as defined above
\newpage


\setcounter{page}{1}

\section*{Abstrakt}
Tato seminární práce pojednává o~problematice extrahování dat z~webu z~praktického hlediska. Cílem této práce je implementace webového scraperu pro vybrané webové stránky. Práce je řešena v~kontextu předmětu 4IZ470 Dolování znalostí z~webu, mezi jehož zaměření patří WCM -- web content mining, tj. dolování, extrakce a~integrace užitečných dat, informací a~znalostí z~webového prostředí. 

Problém je vyřešen pomocí skriptovacího nástroje CasperJS pro automatizaci zobrazování obsahu webových stránek. Skriptování je zhotoveno v~programovacích jazycích JavaScript a~Python. Nejdříve je provedena analýza vybraného webu. Výběr web podléhá míře potenciálu obsažených dat vyhovujících představenému byznysovému záměru. Analýza zahrnuje zkoumání obsahu těchto webů i~jejich struktury. Na základě analýzy je vytvořen algoritmus pro automatizovanou extrakci dat z~těch to webů. 

Výstupem této práce je hotový webobvý scraper a~dokumentace pro jeho konfiguraci a~spuštění. Tento scraper je schopný stahovat data z~webu v~požadovaném tabulkovém formátu. Pro ukázku výstupu je přiloženo několik datových souborů obsahující získané informace pomocí vytvořeného scraperu. Přínosem této práce je uskutečnění smysluplného experimentu nad studií o~struktuře moderních webů a~uvedení jednoho z~mnoha možných, ne-li nejlepších, způsobů získávání dat z~nich.

\section*{Klíčová slova}
Web Content Mining, Web Page Scraping, strukturovaná data, headless prohlížeče,\\ automatizace, skriptování, CasperJS, PhantomJS, JavaScript.

\newpage

 
\tableofcontents

\newpage

\section{Úvod}
Hledání znalostí je v~rámci každé vědecké disciplíny nesmírně důležitým východiskem pro nalezení nových objevů a~invencí. Přítomnost celosvětové sítě WWW a~internetu znamená pro svět významnou akceleraci rozvoje ve všech vědních oblastí za pomocí zpřístupnění enormního množství dat v~otevřeném prostředí. Tato data v~sobě skrývají mnoho byznysu relevantních znalostí, které se mohou velice dobře uplatnit v~dnešním ekonomickém prostředí. Problém je ale jak tato data vůbec získat.

\subsection{Představení problému}
Internet stále řízen čím dál tím masivnějším tokem informací, proto dnes již není tak jednoduché získávat data dle specifických potřeb. Dalším problémem je rychle rostoucí se trend rozvoje webových technologií. Tyto technologie jsou hlavním důvodem zralosti dnešního webového prostředí. To se projevuje zejména v~dynamických webových aplikací, které postupně a~jistě nahrazují tradiční způsob prezentace informací na webu. 

Pro získávání dat z~moderních webů je vyžadováno použití moderních nástrojů, které jsou na příchod nových technologií připraveny. Jedním z~přístupů v~řešení problému dynamického webu z~pohledu získávání webových dat je použití speciálního internetového prohlížeče, který je srovnatelný s~klasickými prohlížeči a~který se navíc dá zautomatizovat. Příkladem takového internetového prohlížeče je PhantomJS \cite{phantomjs} nebo HtmlUnit.

\subsection{Přístup a~cíle}
Internet se dá považovat za distribuované úložiště potenciálních dat, která mají řadu možných způsobů využití. K~tomu, aby data získaná z~webu byla k~něčemu užitečná, zaprvé musí být zajištěna a~zadruhé musí být zpracovávána do akceptovatelné podoby ještě předtím, než budou použity v~dalších fázích dolování znalostí jako např. předzpracování. 

Nejideálnější případ extrakce je, když jsou všechna tato data dostupná na jednom místě v~rámci určitého webu. Skutečnost je ale taková, že často jsou data zpřístupněna v~rozpadlých dávkách podle toho, v~jakém okamžiku jsou pro uživateli jak relevantní během jeho pobytu na daném webu. Zpravidla je žádoucí při extrakci mít všechna data sloučena do jednoho výsledného souboru, což usnadňuje jejich další zpracování. Proto je obvykle potřeba tato data postupně posbírat z~více místech na webu v~různých okamžicích prohlížení. Z~tohoto důvodu je potřeba použít sofistikovanější algoritmus pro zachytávání těch to dat.

Tato práce se zabývá především implementací automatizace extrahování dat pomocí skriptovacího nástroje CasperJS \cite{casperjs}. Implementace bude probíhat hlavně pomocí programovacího jazyka JavaScript s~použitím programovacího rozhraní poskytovaného nástrojem CasperJS v~kombinaci se skriptovacím jazykem Python. Předmětem extrakce je webová stránka s~informacemi o~podnicích různých oborů. Extrahovaná data pak budou sloužit jako podklad pro vývoj určité aplikace, která je hlavním projektem vymýšlené firmy. Cílem práce je tedy vytvoření soubor webových scraperů pro automatické získávání těchto dat.

\subsection{Postup práce}
Práce je rozčleněna do následujících částí, přičemž jejich pořadí vychází ze skutečného postupování a~krokování v~práci.
\begin{enumerate}
\item Diskuze o~problematice moderního webu
\item Představení byznysového záměru
\item Výběr vhodné webové stránky
\item Implementace scraperu
\item Zápis dokumentace vytvořeného programu
\end{enumerate}

\subsection{Používané nástroje a~knihovny}
Vybraným nástrojem pro implementaci web scraper v~rámci této práce je CasperJS. Tento open-source nástroj slouží ke skriptování prohlížeče a~jeho automatizaci. Primárně je CasperJS navržen pro použití s~headless WebKit prohlížečem PhantomJS a~sekundárně s~Gecko prohlížečem SlimerJS. Pro účely extrahování dat je dostačující použít jen PhantomJS.

O~nástrojích CasperJs a~PhantomJS jsem se dozvěděl v~průběhu studia vedlejší specializace 4KS Řízení kvality softwaru. PhantomJS byl v~rámci předmětu Automatizované funkční testování softwaru jedním z~hlavních prostředků pro automatizaci testování webových aplikací. Po přečtení jeho dokumentace jsem si uvědomil o~jeho možném uplatnění v~oblasti extrakce webových dat. Ukázalo se, že PhantomJS a~CasperJS jsou vhodnými nástroji i~pro extrakci dat, obzvlášť pokud jde o~stahování dat z~moderních dynamických webových stránek.

V rámci CasperJS a~PhantomJS lze psát běžné JavaScriptové kódy a~proto je možné využít všech výhod a~standardních funkcí tohoto programovacího jazyka. Pomocí těchto nástrojů je možné vytvořit plnohodnotný skript pro zachycení a~simulaci případu užití běžného uživatele včetně jeho interakce s~webovými stránkami včetně přesměrovávání a~odesílání formulářů.

Pro účely extrakce dat přímo z~dokumentového objektu webové stránky je navíc použita knihovna jQuery. Tato knihovna slouží k~usnadnění procházení jednotlivých HTML tagů a~parsování čistá data z~nich.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Moderní web}
Obsahem této kapitoly je diskuze o~problému moderního webu z~technického hlediska extrakce webových dat.

S rychlým růstem webových technologií roste i~složitost získávání dat. Dnešním trendem ve vývoji webových aplikací spočívá v~použití a~integrace různých revolučních technologií jako AJAX, WebSocket, ServiceWorker, WebStorage a~dalších frontendových frameworků jako AnglularJS a~ReactJS k~vytváření lepšího prostředí pro interakce s~uživateli. Dále tyto weby bývají navrženy jako single-page aplikace, která zlepšuje uživatelskou přívětivost a~výkonnost systému. To však ale znamená, že weby se stávají dynamickými \cite{kelk}, což zkomplikuje proces extrakce dat z~nich.

Všechny tyto technologie přináší na webové prostředí z~hlediska systémového návrhu odlišný přístup v~zobrazování informací uživatelům. Tento princip spočívá v~dodatečném načítání informačních zdrojů až v~okamžiku, kdy je to potřeba, např. pomocí stránkování. Dále se jedná o~dynamičnosti webové stránky, kdy struktura dokumentového objektu webové stránky se mění v~závislosti na interakce uživatele. To vše se děje asynchronně v~pozadí aplikace. Tyto změny však uživatelé nepoznají, ale pro účely extrakce dat to znamená složité simulace těchto událostí, bez které není šance získat požadovaná data. 

Dalším problémem je bezpečnost webů. Bezpečnost vychází z~potřeby ochrany webu před útokem a~spamováním. Bezpečnostní prvky jsou překážkou pro automatizované prohlížení webů, protože to může být vyhodnoceno jako spamování, jelikož aktivity robotů jsou nežádoucí a~zatěžují výkon serveru. Někteří provozovatelé mají své weby navržené tak, aby omezili chod automatických robotů na jejich stránky, a~to nejen z~důvodu zajištění rychlosti systému a~zamezení úniku dat. Příkladem takové ochrany je bezplatná služba Google reCAPTCHA, který slouží jako brána pro detekce robotu vs. člověka na základě rozpoznávání znaků a~objektů na obrázku, což je pro člověka snadné, ale pro počítače velmi těžké.

Jedním z~možných řešení zmíněných problémů (kromě ochrany reCAPTCHA) spočívá v~skutečné simulaci uživatelských interakcí s~webovou stránkou. K~tomu je zřejmě potřeba webový prohlížeč, avšak takový, který se dá zautomatizovat.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Popis nástroje CasperJS}
Jak už bylo zmíněno, CasperJS představuje systém pro skriptování a~simulaci headless webového prohlížeče PhantomJS. To znamená, že pomocí tohoto prohlížeče lze automatizovaně navštěvovat webové stránky a~extrahovat data ze stažených zdrojů. Ve skriptu pro CasperJS lze definovat logiku pro interakci s~webem a~extrakci dat. Kromě základních interakcí s~webovou stránkou jako klikání a~simulace klávesových vstupů je možné předat funkci pro extrakci do konzole prohlížeče pomocí funkce \texttt{evaluate}, která vrátí výstup předaného kódu \cite{hayton}.

Výhoda použití CasperJS a~PhantomJS spočívá v~plnohodnotném renderování stránek včetně dynamicky generovaných prvků na stránce a~načítání asynchronních požadavků. PhantomJS zajišťuje přítomnost všech datových zdrojů tak, jako kdyby byla stránka navštívena normálním prohlížečem. Další výhodou tohoto prohlížeče je, že nemá grafické rozhraní. Veškerá renderování se vykovávají v~paměti a~proto je výrazně rychlejší než normální prohlížeče s~grafickým rozhraním \cite{greco}. Díky tomu lze podstatně zrychlit proces procházení webovými stránkami a~soustředit se na samotná data, která jsou pro účely extrakce relevantní.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Byznysový záměr}
Cílem zamýšleného byznysu je vytvořit jednotnou platformu pro poskytování informací ohledně místních služeb všech druhů. Jedná se o~mobilní vyhledávač a~aplikaci pro rezervaci služeb. Tento systém umožňuje vyhledávání, srovnávání a~rezervaci služeb nabízených  nejen v~okolí pobytu uživatele. 

Výhoda této aplikace je jednoduchá dostupnost užitečných informací o~podnicích, které obchodují nebo nabízejí služby jako catering, péče o~tělo, fitness, zdraví apod. Tato aplikace také zahrnuje hodnocení jednotlivých služeb na základě uživatelského feedbacku. V~aplikaci lze zobrazovat nejbližší pobočky podle typů nabízených služeb, ceny, hodnocení a~dalších vlastností. Základním případem užití je hledání nejbližších poboček na základě otevírací doby a~uživatelem specifikované služby včetně rezervace této služby. Systém navíc integruje atraktivní funkce jako zobrazení lokací a~navigace.

Tato platforma pro vyhledávání služeb nabízí místním byznysům možnost zapojení do programu k~tomu, aby svá podnikání prohlásili za jejich vlastní a~začali spravovat své služby v~této aplikaci. Jenže tento proces je mnohdy složitý a~kvůli tomu není velká motivace pro vlastníky firem. Proto je zpočátku akvizice zákazníků potřeba připravit data o~těchto místních podnicích, aby se ulehčila migrace jejích informací do aplikace. Je tedy potřeba najít způsob, jak přetransformovat informace na webových stránkách zákazníků do backendu aplikace.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Výběr cíle extrakce}
Předmětem extrakce informací jsou zlaté stránky, protože obsahuje profily firem včetně užitečných informací o~nich. Každá země má své vlastní zlaté stránky, které obsahují informace především jen o~zdejších podnicích. Pro účely této práce byly zvoleny švýcarské zlaté stránky na adrese \url{https://yellow.local.ch/en} k~extrakci dat.

Zlaté stránky je webový portál, který slouží jako jako komerční rejstřík společností. Hlavním obsahem toho to webu je katalog firem a~telefonní seznam. Tyto stránky poskytují službu vyhledávání firem podle klíčových slov, lokací a~zároveň umožňují filtraci a~seřazení výsledků. Kromě vyhledávání firem lze v~rámci zlatých stránkách také vyhledávat produkty, jídelní menu, články a~událostí. Zlaté stránky jsou komerční prostředí, proto je např. ovlivněno pořadí vyhledávacích výsledků. Pro účely extrakce je žádoucí spíše se přiklánět k~úplnosti než k~přesnosti dat, protože v~první fázi projektu je snahou mít co nejvíce dat ke zpracování.

\subsection{Obsah a~struktura webu}
Základní vyhledávání spočívá v~upřesnění kategorie a~lokace služeb. Po zadání a~potvrzení klíčového slova služby a~uživatelem zvoleného místa se zobrazí výsledky vyhledávání. Např. jestli je potřeba najít kadeřnictví v~hlavním městě Curych, tak se zadá klíčové slovo \uv{hairdressers} a~vedle ještě název hlavního města, tj. \uv{Zurich}. Výsledky se zobrazují na samostatné stránce jako seznam s~informacemi o~jednotlivých firmách. V~případě většího množství nalezených výsledků je tento seznam rozdělen do více stránek, tj. stránkování.

Seznam výsledků obsahuje informace o~podniku jako název, hodnocení, typy služeb, adresa, telefonní číslo, URL adresa a~další meta informace jako doporučení, oblíbenost. Další podrobnosti o~firmě lze zobrazit kliknutím na tlačítko \uv{Information \& Details}, které uživatele přesměruje na další stránku s~detaily nalezeného výsledku. Zde je možné navíc zjistit otevírací dobu a~mapové souřadnice pobočky.

\subsection{Strategie získávání dat}
Pro zajištění nejrelevantnějších dat je ponecháno defaultní řazení výsledků, tj. podle relevance. Vyhledávání se provádí na základě seznamu klíčových slov služeb a~seznamu názvů měst. Města jsou seřazena vzestupně podle počtu obyvatelů. Pro každé město jsou vyhledávána všechna uvedená klíčová slova. Proto je počet vyhledávání roven počtu měst krát počet klíčových slov. 

Názvy měst a~klíčová slova jsou uvedeny v~tabulce \ref{cityandkeywords}. Pro demonstrační účely této práce bylo zvoleno 11 názvů měst a~11 klíčových slov. Počet kombinací je tedy součin počtu měst a~počtu klíčových slov. Tedy $ 11 \times 11 = 121 $. K~názvům měst a~klíčovým slovům lze samozřejmě přidávat o~další pojmy.

\begin{table}[ht]
\centering
\begin{tabular}{rll}
\textbf{\#} & \textbf{Město} & \textbf{Klíčové slovo}                                        \\
\hline
1  & Zurich                             & bar                                        \\
2  & Geneve                             & catering                                   \\
3  & Basel                              & kebab                                      \\
4  & Lausanne                           & pizza                                      \\
5  & Bern                               & pharmacy                                   \\
6  & Winterthur                         & optician                                   \\
7  & Luzern                             & massage                                    \\
8  & St. Gallen                         & garrage                                    \\
9  & Lugano                             & hotel                                      \\
10 & Bienne                             & nails                                      \\
11 & Bellinzona                         & florist           
\end{tabular}
\caption{Názvy měst a~klíčová slova služeb}
\label{cityandkeywords}
\end{table}

Scraper bude iterovat v~těchto kombinacích a~pro každou kombinaci bude jeden generovat soubor s~extrahovanými daty v~tabulkovém formátu. Počet záznamů v~každém souboru závisí na množství nalezených výsledků. Každý záznam bude obsahovat následující informace: název města, klíčové slovo, název podniku, adresa podniku, URL adresa webu, telefonní číslo, email, souřadnice, popis, a~otevírací dobu.

Další ze zjištěných vlastností švýcarských zlatých stránek je, že je možné vyhledávat také pomocí URL odkazů. Např. adresa \url{https://yellow.local.ch/en/q/Zurich/restaurant.html?&rid=cv_i} přímo odkazuje na první stránku s~výsledky vyhledávání pro restaurace v~Curychu. Této vlastnosti lze využít při iteraci v~kombinacích klíčových slov a~názvů měst. To znamená, že již není potřeba projít klasickým procesem vyhledávání na domovské stránce tohoto webu, ale bohatě stačí zadávat patřičné odkazy.

\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementace}
Základem implementace scraperu v~CasperJS je zavolání konstruktoru pro vytvoření instance CasperJS objektu. Další postup bylo vytvoření tzv. fronty jednotlivých kroků, které se mají vykonat za sebou. Kroky se vykonávají v~pořadí FIFO. Základní skript pro spuštění CasperJS vypadá následovně.

\begin{lstlisting}[caption=Základní skript pro CasperJS]
var casper = require("casper").create();
casper.start();
casper.then(function () {   // creating a step in the queue
    casper.echo("Step 1");
});
casper.then(function () {   // creating a step in the queue
    casper.echo("Step 2");
});
casper.run();
\end{lstlisting}

Použití tohoto způsobu krokování je potřebné pro zajištění správné následnosti procházení webu, tj. zvládnutí asynchronních požadavků a~čekání na dynamicky generovaný obsah webové stránky. Podstatnou roli zde hraje Promise framework, který je součástí nástroje CasperJS. Tento framework slouží k~řízení asynchronních příkazů v~rámci javascriptového programu \cite{sugrue}.

Pro procházení stránkování byla použita technika \texttt{label} a~\texttt{goto}, která umožňuje opakovat určité části kódu v~CasperJS. Pro samotnou extrakci dat je vytvořena jedna funkce, která parsuje obsah HTML dokumentu v~čistá data. Zde byla použita knihovna jQuery.

Pro konfiguraci nástroje CasperJS v~rámci jeho konstruktoru byla nastavena možnost ignorování stahování obrázkových dat pro zrychlení běhu scraperu tím, že se výrazně sníží množství přenesených dat v~síti. Obrázky jsou ignorovány také z~důvodu, že jsou vzhledem k~byznysovému záměru skoro nepoužitelné.

Implementovaný scraper zaznamenává průběh svého spuštění pomocí standardního textového logování do souboru. Logování je důležité pro detekci chyb a~pro sledování výkonu a~stavu běžícího program. Proces scraping mnohdy zabírá velké množství času v~závislosti na množství vstupu, tj. klíčová slova pro vyhledávání, proto je nezbytně nutné průběžně logovat každý důležitý krok programu.

Program je složen ze dvou částí. První část se zabývá vytvořením instancí CasperJS pro vyhledávání pro jednu kombinaci klíčového slova a~názvu města. Tato část se zavolá příkazem \texttt{casperjs}, viz README. Předmětem druhé části je opakované zavolání první části programu v~iteraci po všech kombinacích klíčových slov a~názvů měst. Tato druhá část je implementována v~programovacím jazyce Python, kde se jedná pouze o~načítání vstupních hodnot pro parametrizaci samotnému scraperu CasperJS. Obě implementované části jsou parametrizovatelné a~parametry se zadávají do příkazového řádku při spuštění scraperu.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dokumentace programu}
Dokumentace vytvořeného scraperu je napsaná pomocí syntaxe MarkDown a~je k~dispozici jako README na domovské stránce projektu gitového repozitáře. Tato dokumentace popisuje návod pro konfiguraci spuštění scraperu. Přečtení této dokumentace je nezbytně nutné k~pochopení základního principu implementovaného scraperu.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Závěr}
Tato práce se zabývala vytvořením webového scraperu pro automatické extrahování dat ze švýcarských zlatých stránek. Předmětem extrakce byly informace o~firmách různých oborů. Výstupem této práce je hotový projekt včetně dokumentace popisující návod pro konfiguraci a spuštění scraperu. K~projektu jsou připojena ukázková data, která jsou rozdělena dle názvů měst ve Švýcarsku.

Hlavním přínosem této práce je pochopení principu Web Page Scrapingu s~použitím headless prohlížeče a~rovněž i~praktické zhotovení funkčního webového scraperu. Výstupní projekt je ukázkou toho, jak by se dalo naprogramovat scraper pomocí nástroje CasperJS. Tato práce může koneckonců sloužit jako podklad pro podobné budoucí projekty zahrnující extrahování dat z~webových stránek.

\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{acm}
\bibliography{pmc}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Přílohy}
\begin{itemize}
\item Projekt je publikován pod open-source licencí MIT na gitovém repozitáři \\ \url{https://github.com/nvbach91/4IZ470} 
\item Zdrojový kód projektu se nachází ve složce \texttt{project}.
\item Zdrojový kód textu práce se nachází ve složce \texttt{paper}.
\end{itemize}


\end{document}