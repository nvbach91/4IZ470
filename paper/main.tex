\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[IL2]{fontenc}
\usepackage[czech]{babel}

\usepackage[a4paper,top=3cm,bottom=4cm,left=3.5cm,right=3cm,marginparwidth=1.75cm]{geometry}

\usepackage{amsmath}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{listings}
\usepackage{color}


% DON'T HYPHENATE THESE PLEASE
\hyphenation{JavaScript}

% CODE LISTING CONFIG
\definecolor{lightgray}{rgb}{.9,.9,.9}
\definecolor{orange}{rgb}{.694,.369,.236}
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{darkbrown}{rgb}{.655,.349,.125}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}
\definecolor{darkgreen}{rgb}{.298, .565, .404}

\lstdefinelanguage{JavaScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={require, then, start, create, echo, run, class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkbrown}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{darkgreen}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}
\lstset{
   language=JavaScript,
   backgroundcolor=\color{white},
   extendedchars=true,
   basicstyle=\footnotesize\ttfamily,
   showstringspaces=false,
   showspaces=false,
   numbers=left,
   numberstyle=\footnotesize,
   numbersep=9pt,
   tabsize=2,
   breaklines=true,
   showtabs=false,
   captionpos=b
}

\renewcommand{\lstlistingname}{Ukázka kódu}% Listing -> Algorithm
\renewcommand{\lstlistlistingname}{Seznam ukázek kódů \lstlistingname s}

\newcommand{\HRule}[1]{\rule{\linewidth}{#1}}           % Horizontal rule

\makeatletter                                           % Title
\def\printtitle{                       
    {\centering \@title\par}}
\makeatother                                    

\makeatletter                                           % Author
\def\printauthor{                   
    {\centering \large \@author}}                
\makeatother                            

\title{   \normalsize\textsc {
          \large{Vysoká škola ekonomická v~Praze}\\[0.3cm]    
          \large{Fakulta informatiky a~statistiky}\\[0.3cm]
          \large{Katedra informačního a~znalostního inženýrství}\\
        }
\textsc{}                                               % Subtitle
            \\[7.0cm]                                   % 2cm spacing
            \huge \textbf{Web Scraping s~CasperJS}      % Title
            \HRule{2pt} \\ [0.4cm]                      % Lower rule + 0.5cm spacing
            \normalsize \textbf{4IZ470 Dolování znalostí z~webu}
        }

\author{\raggedright
        Student: Bc. Viet Bach Nguyen \\
        Vyučující: doc. Ing. Vojtěch Svátek, Dr. \\
        Datum: \today
}

\setlength{\parskip}{0.5em}
\setlength{\parindent}{2em}
\renewcommand{\baselinestretch}{1.2}

\begin{document}

\thispagestyle{empty}           % Remove page numbering on this page

\printtitle                     % Print the title data as defined above
      \vfill
\printauthor                    % Print the author data as defined above
\newpage


\setcounter{page}{1}

\section*{Abstrakt}
Tato seminární práce pojednává o~problematice extrahování dat z~webu z~praktického hlediska. Cílem této práce je implementace webového scraperu pro vybrané webové stránky. Práce je řešena v~kontextu předmětu 4IZ470 Dolování znalostí z~webu, mezi jehož zaměření patří WCM -- web content mining, tj. dolování, extrakce a~integrace užitečných dat, informací a~znalostí z~webového prostředí. 

Problém je vyřešen pomocí skriptovacího nástroje CasperJS pro automatizaci zobrazování obsahu webových stránek. Skriptování je zhotoveno v~programovacích jazycích JavaScript a~Python. Nejdříve je provedena analýza vybraných webů. Výběr těchto webů podléhá míře potenciálu obsažených dat vyhovujících byznysovému záměru. Analýza zahrnuje zkoumání obsahu těchto webů i~jejich struktury. Na základě analýzy je vytvořen algoritmus pro automatizovanou extrakci dat z~těch to webů. 

Výstupem této práce je hotový web scraper a~dokumentace pro jeho konfiguraci a~spuštění. Tento scraper je schopný stahovat data z~webu v~požadovaném tabulkovém formátu, jehož sloupce lze nadefinovat v~konfiguračním souboru. Pro ukázku výstupu je přiloženo několik datových souborů obsahující získané informace pomocí vytvořeného scraperu. Přínosem této práce je uskutečnění smysluplného experimentu nad studií o~struktuře moderních webů a~uvedení jednoho z~mnoha možných, ne-li nejlepších, způsobů získávání dat z~nich.

\section*{Klíčová slova}
Web Content Mining, Web Scraping, strukturovaná data, headless prohlížeče,\\ automatizace, skriptování, CasperJS, PhantomJS, JavaScript.

\newpage

 
\tableofcontents

\newpage

\section{Úvod}
Hledání znalostí je v~rámci každé vědecké disciplíny nesmírně důležitým východiskem pro nalezení nových objevů a~invencí. Přítomnost celosvětové sítě WWW a~internetu znamená pro svět významnou akceleraci rozvoje ve všech vědních oblastí za pomocí zpřístupnění enormního množství dat v~otevřeném prostředí. Tato data v~sobě skrývají mnoho byznysu relevantních znalostí, které se mohou velice dobře uplatnit v~dnešním ekonomickém prostředí. Problém je ale jak tato data vůbec získat.

\subsection{Představení problému}
Internet stále řízen čím dál tím masivnějším tokem informací, proto dnes již není tak jednoduché získávat data dle specifických potřeb. Dalším problémem je rychle rostoucí se trend rozvoje webových technologií. Tyto technologie jsou hlavním důvodem zralosti dnešního webového prostředí. To se projevuje zejména v~dynamických webových aplikací, které postupně a~jistě nahrazují tradiční způsob prezentace informací na webu. 

Pro získávání dat z~moderních webů je vyžadováno použití moderních nástrojů, které jsou na příchod nových technologií připraveny. Jedním z~přístupů v~řešení problému dynamického webu z~pohledu získávání webových dat je použití speciálního internetového prohlížeče, který je srovnatelný s~klasickými prohlížeči a~který se navíc dá zautomatizovat. Příkladem takového internetového prohlížeče je PhantomJS\cite{phantomjs} nebo HtmlUnit.

\subsection{Přístup a~cíle}
Internet se dá považovat za distribuované úložiště potenciálních dat, která mají řadu možných způsobů využití. K~tomu, aby data získaná z~webu byla k~něčemu užitečná, zaprvé musí být zajištěna a~zadruhé musí být zpracovávána do akceptovatelné podoby ještě předtím, než budou použity v~dalších fázích dolování znalostí jako např. předzpracování. 

Nejideálnější případ extrakce je, když jsou všechna tato data dostupná na jednom místě v~rámci určitého webu. Skutečnost je ale taková, že často jsou data zpřístupněna v~rozpadlých dávkách podle toho, v~jakém okamžiku jsou pro uživateli jak relevantní během jeho pobytu na daném webu. Zpravidla je žádoucí při extrakci mít všechna data sloučena do jednoho výsledného souboru, což usnadňuje jejich další zpracování. Proto je obvykle potřeba tato data postupně posbírat z~více místech na webu v~různých okamžicích prohlížení. Z~tohoto důvodu je potřeba použít sofistikovanější algoritmus pro zachytávání těch to dat.

Hlavní obsah této práce se zabývá implementací automatizace extrahování dat pomocí skriptovacího nástroje CasperJS\cite{casperjs}. Implementace bude probíhat v~programovacím jazyce JavaScript s~použitím programovacího rozhraní poskytovaného nástrojem CasperJS. Předmětem extrakce budou weby s~informacemi o~podnicích různých oborů. Extrahovaná data pak budou sloužit jako podklad pro vývoj určité aplikace, která je hlavním projektem vymýšlené firmy. Cílem práce je tedy vytvoření soubor webových scraperů pro automatické získávání těchto dat.

\subsection{Postup práce}
Práce je rozčleněna do následujících částí, přičemž jejich pořadí vychází ze skutečného postupování a~krokování v~práci.
\begin{enumerate}
\item Rozbor problematiky moderního webu
\item Představení byznysového záměru
\item Výběr vhodné webové stránky
\item Implementace scraperu
\item Zápis dokumentace vytvořeného programu
\end{enumerate}

\subsection{Používané nástroje a~knihovny}
Vybraným nástrojem pro implementaci web scraper v~rámci této práce je CasperJS. Tento open-source nástroj slouží ke skriptování prohlížeče a~jeho automatizaci. Primárně je CasperJS navržen pro použití s~headless WebKit prohlížečem PhantomJS a~sekundárně s~Gecko prohlížečem SlimerJS. Pro účely extrahování dat je dostačující použít jen PhantomJS. 

V rámci CasperJS a~PhantomJS lze psát běžné JavaScriptové kódy a~proto je možné využít všech výhod a~standardních funkcí tohoto programovacího jazyka. Pomocí těchto nástrojů je možné vytvořit plnohodnotný skript pro zachycení a~simulaci případu užití běžného uživatele včetně jeho interakce s~webovými stránkami včetně přesměrovávání a~odesílání formulářů.

Pro účely extrakce dat přímo z~dokumentového objektu webové stránky je navíc použita knihovna jQuery. Tato knihovna slouží k~usnadnění procházení jednotlivých HTML tagů a~parsování čistá data z~nich.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Moderní web}
Obsahem této kapitoly je diskuze o~problému moderního webu z~hlediska extrakce webových dat.

S rychlým růstem webových technologií roste i~složitost získávání dat. Dnešním trendem ve vývoji webových aplikací spočívá v~použití a~integrace různých revolučních technologií jako AJAX, WebSocket, ServiceWorker, WebStorage a~další k~vytváření lepšího prostředí pro interakce s~uživateli. Dále tyto weby bývají navrženy jako single-page aplikace, která zlepšuje uživatelskou přívětivost a~výkonnost systému. To však ale znamená, že weby se stávají dynamickými, což zkomplikuje proces extrakce dat z~nich.

Všechny tyto technologie přináší na webové prostředí z~hlediska systémového návrhu odlišný přístup v~zobrazování informací uživatelům. Tento princip spočívá v~dodatečném načítání informačních zdrojů až v~okamžiku, kdy je to potřeba, např. pomocí stránkování. Dále se jedná o~dynamičnosti webové stránky, kdy struktura dokumentového objektu webové stránky se mění v~závislosti na interakce uživatele. To vše se děje asynchronně v~pozadí aplikace. Tyto změny však uživatelé nepoznají, ale pro účely extrakce dat to znamená složité simulace těchto událostí, bez které není šance získat určená data. 

Dalším problémem je bezpečnost webů. Bezpečnost vychází z~potřeby ochrany webu před útokem a~spamováním. Bezpečnostní prvky jsou překážkou pro automatizované prohlížení webů, protože to může být vyhodnoceno jako spamování, jelikož aktivity robotů jsou nežádoucí a~zatěžují výkon serveru. Někteří provozovatelé mají své weby navržené tak, aby omezili chod automatických robotů na jejich stránky, z~důvodu zajištění rychlosti a~zamezení úniku dat. Příkladem takové ochrany je bezplatná služba Google reCAPTCHA, který slouží jako brána pro detekce robotu vs. člověka na základě rozpoznávání znaků a~objektů na obrázku, což je pro člověka snadné, ale pro počítače velmi těžké.

Jedním z~možných řešení zmíněných problémů (kromě ochrany reCAPTCHA) spočívá v~skutečné simulaci uživatelských interakcí s~webovou stránkou. K~tomu je zřejmě potřeba webový prohlížeč, avšak takový, který se dá zautomatizovat.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Popis nástroje CasperJS}
Jak už bylo zmíněno, CasperJS představuje systém pro skriptování a~simulaci headless webového prohlížeče PhantomJS. To znamená, že pomocí tohoto prohlížeče lze automatizovaně navštěvovat webové stránky a~extrahovat data ze stažených zdrojů. Ve skriptu pro CasperJS lze definovat logiku pro interakci s~webem a~extrakci dat. Kromě základních interakcí s~webovou stránkou jako klikání a~simulace klávesových vstupů je možné předat funkci pro extrakci do konzole prohlížeče pomocí funkce \texttt{evaluate}, která vrátí výstup provedeného předaného kódu.

Výhoda použití CasperJS a~PhantomJS spočívá v~plnohodnotném renderování stránek včetně dynamicky generovaných prvků na stránce a~načítání asynchronních požadavků. PhantomJS zajišťuje přítomnost všech datových zdrojů tak, jako kdyby byla stránka navštívena normálním prohlížečem.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Byznysový záměr}
Cílem zamýšleného byznysu je vytvořit jednotnou platformu pro poskytování informací ohledně místních služeb. Jedná se o~mobilní vyhledávač a~aplikaci pro rezervaci služeb. Tento systém umožňuje vyhledávání, srovnávání a~rezervaci služeb nejen v~místě pobytu uživatele. 

Výhoda této aplikace je jednoduchá dostupnost užitečných informací o~podnicích, které nabízejí služby jako restaurace, péče o~tělo, fitness, zdraví apod. Aplikace také zahrnuje hodnocení jednotlivých služeb na základě uživatelského feedbacku. V~aplikaci lze zobrazovat nejbližší pobočky podle typů nabízených služeb, ceny, hodnocení aj. Základním případem užití je hledání nejbližších poboček na základě otevírací doby a~uživatelem specifikované služby včetně rezervace této služby. Aplikace navíc integruje atraktivní funkce jako mapové zobrazení lokací a~navigace.

Tato platforma pro vyhledávání služeb vyžaduje zapojení místních byznysů k~tomu, aby svá podnikání prohlásili za jejich vlastní a~začali spravovat své služby v~této aplikaci. Jenže tento proces je mnohdy složitý a~kvůli tomu není velká motivace pro vlastníky firem. Proto je zpočátku akvizice zákazníků potřeba připravit data o~těchto místních podnicích, aby se ulehčila migrace jejích informací do aplikace. Je tedy potřeba najít způsob, jak přetransformovat informace na webových stránkách zákazníků do backendu aplikace.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Výběr cíle extrakce}
Předmětem extrakce informací jsou zlaté stránky, protože obsahuje profily firem včetně užitečných informací o~nich. Každá země má své vlastní zlaté stránky, které obsahují informace jen o~místních podnicích. Pro účely této práce byly zvoleny švýcarské zlaté stránky na adrese \url{https://yellow.local.ch/en/} k~extrakci dat.

Zlaté stránky je webový portál, který slouží jako jako komerční rejstřík společností. Hlavním obsahem toho to webu je katalog firem a~telefonní seznam. Tyto stránky poskytují službu vyhledávání firem podle klíčových slov, lokací a~zároveň umožňují filtraci a~seřazení výsledků. Kromě vyhledávání firem lze v~rámci zlatých stránkách také vyhledávat produkty, jídelní menu, články a~událostí. Zlaté stránky jsou komerční prostředí, proto je např. ovlivněno pořadí vyhledávacích výsledků.

\subsection{Obsah a~struktura webu}
Základní vyhledávání spočívá v~upřesnění kategorie a~lokace služeb. Po zadání a~potvrzení klíčového slova služby a~uživatelem zvoleného místa se zobrazí výsledky vyhledávání. Např. jestli je potřeba najít kadeřnictví v~hlavním městě Curych, tak se zadá klíčové slovo \uv{hairdressers} a~vedle ještě název hlavního města, tj. \uv{Zurich}. Výsledky se zobrazují na samostatné stránce jako seznam s~informacemi o~jednotlivých firmách. V~případě většího množství nalezených výsledků je tento seznam rozdělen do více stránek, tj. stránkování.

Seznam výsledků obsahuje informace o~podniku jako název, hodnocení, typy služeb, adresa, telefonní číslo, URL adresa a~další meta informace jako doporučení, oblíbenost. Další podrobnosti o~firmě lze zobrazit kliknutím na tlačítko \uv{Information \& Details}, které uživatele přesměruje na další stránku s~detaily nalezeného výsledku. Zde je možné navíc zjistit otevírací dobu a~mapové souřadnice pobočky.

\subsection{Strategie získávání dat}
Pro zajištění nejrelevantnějších dat je ponecháno defaultní řazení výsledků, tj. podle relevance. Vyhledávání se provádí na základě seznamu klíčových slov služeb a~seznamu názvů měst. Města jsou seřazena vzestupně podle počtu obyvatelů. Pro každé město jsou vyhledávána všechna uvedená klíčová slova. Proto je počet vyhledávání roven počtu měst krát počet klíčových slov. Názvy měst a~klíčová slova jsou uvedeny v~následující tabulce. Názvů měst je 11 a~klíčových slov je 11. Počet kombinací je tedy $ 11 \times 11 = 121 $.

\begin{table}[ht]
\centering
\begin{tabular}{rll}
\textbf{\#} & \textbf{Město} & \textbf{Klíčové slovo}                                        \\
\hline
1  & Zurich                             & bar                                        \\
2  & Geneve                             & catering                                   \\
3  & Basel                              & kebab                                      \\
4  & Lausanne                           & pizza                                      \\
5  & Bern                               & pharmacy                                   \\
6  & Winterthur                         & optician                                   \\
7  & Luzern                             & massage                                    \\
8  & St. Gallen                         & garrage                                    \\
9  & Lugano                             & hotel                                      \\
10 & Bienne                             & nails                                      \\
11 & Bellinzona                         & florist           
\end{tabular}
\caption{Názvy měst a~klíčová slova služeb}
\end{table}

Scraper bude iterovat v~těchto kombinacích a~pro každou kombinaci bude jeden generovat soubor s~extrahovanými daty v~tabulkovém formátu. Počet záznamů v~každém souboru závisí na množství nalezených výsledků. Každý záznam bude obsahovat následující informace: název města, klíčové slovo, název podniku, adresa podniku, URL adresa webu, telefonní číslo, email, souřadnice, popis, a~otevírací dobu.

Na švýcarských zlatých stránkách lze vyhledávat také pomocí URL odkazů. Např. \url{https://yellow.local.ch/en/q?what=restaurant&where=Zurich&rid=cv_i} přímo odkazuje na výsledky vyhledávání pro restaurace v~Curychu. Toto lze použít při iteraci kombinacemi klíčových slov a~názvů měst.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementace}
Základem implementace scraperu v~CasperJS je zavolání konstruktoru pro vytvoření instance CasperJS objektu. Další postup bylo vytvoření tzv. fronty jednotlivých kroků, které se mají vykonat za sebou. Kroky se vykonávají v~pořadí FIFO. Základní skript pro spuštění CasperJS vypadá následovně.

\begin{lstlisting}[caption=Základní skript pro CasperJS]
var casper = require("casper").create();
casper.start();
casper.then(function () {   // creating a step in the queue
    casper.echo("Step 1");
});
casper.then(function () {   // creating a step in the queue
    casper.echo("Step 2");
});
casper.run();
\end{lstlisting}

Použití tohoto způsobu krokování je potřebné pro zajištění správné následnosti procházení webu, tj. zvládnutí asynchronních požadavků a~čekání na dynamicky generovaný obsah webové stránky.

Pro procházení stránkování byla použita technika \texttt{label} a~\texttt{goto}, která umožňuje opakování části kódu v~CasperJS. Pro samotnou extrakci dat je vytvořena jedna funkce, která parsuje obsah HTML dokumentu v~čistá data. Zde byla použita knihovna jQuery.

V rámci konfigurace nástroje CasperJS byla nastavena možnost ignorování stahování obrázkových dat pro zrychlení běhu scraperu tím, že se výrazně sníží množství přenesených dat v síti. Obrázky jsou jsou ignorovány také z důvodu, že jsou vzhledem k byznysovému záměru skoro nepoužitelné.

Implementovaný scraper zaznamenává průběh svého spuštění pomocí standardního textového logování do souboru. Logování je důležité pro detekci chyb a~pro sledování výkonu a~stavu běžícího program. Proces scraping mnohdy zabírá velké množství času v~závislosti na množství vstupu, tj. klíčová slova pro vyhledávání, proto je nezbytně nutné průběžně logovat každý důležitý krok programu.

Program je složen ze dvou částí. První část se zabývá vytvořením instancí CasperJS pro vyhledávání pro jednu kombinaci klíčového slova a~názvu města. Tato část se zavolá příkazem \texttt{casperjs}, viz README. Druhá část je opakované zavolání první části programu v~iteraci po všech kombinacích klíčových slov a~názvů měst. Tato část je implementována v~programovacím jazyce Python. Obě části jsou parametrizovatelné a~parametry se zadávají do příkazového řádku při spuštění scraperu.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dokumentace programu}
Dokumentace vytvořeného scraperu je napsaná pomocí syntaxe MarkDown a~je k~dispozici jako README na domovské stránce projektu gitového repozitáře. Tato dokumentace popisuje návod pro konfiguraci spuštění scraperu. Přečtení této dokumentace je nezbytně nutné k~pochopení základního principu implementovaného scraperu.


\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{acm}
\bibliography{pmc}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Přílohy}
\begin{itemize}
\item Projekt je publikován pod open-source licencí MIT na gitovém repozitáři \\ \url{https://github.com/nvbach91/4IZ470} 
\item Zdrojový kód projektu se nachází ve složce \texttt{project}.
\item Zdrojový kód textu práce se nachází ve složce \texttt{paper}.
\end{itemize}


\end{document}